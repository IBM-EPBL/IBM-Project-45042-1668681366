{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "\nfrom google.colab import drive\ndrive.mount('/content/drive')\nMounted at /content/drive\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\ndf=pd.read_csv(r'/content/drive/MyDrive/kidney_disease.csv')\nprint(\"The dataset shape is {}\".format(df.shape))\nThe dataset shape is (400, 26)\ndf.head()\nid\tage\tbp\tsg\tal\tsu\trbc\tpc\tpcc\tba\t...\tpcv\twc\trc\thtn\tdm\tcad\tappet\tpe\tane\tclassification\n0\t0\t48.0\t80.0\t1.020\t1.0\t0.0\tNaN\tnormal\tnotpresent\tnotpresent\t...\t44\t7800\t5.2\tyes\tyes\tno\tgood\tno\tno\tckd\n1\t1\t7.0\t50.0\t1.020\t4.0\t0.0\tNaN\tnormal\tnotpresent\tnotpresent\t...\t38\t6000\tNaN\tno\tno\tno\tgood\tno\tno\tckd\n2\t2\t62.0\t80.0\t1.010\t2.0\t3.0\tnormal\tnormal\tnotpresent\tnotpresent\t...\t31\t7500\tNaN\tno\tyes\tno\tpoor\tno\tyes\tckd\n3\t3\t48.0\t70.0\t1.005\t4.0\t0.0\tnormal\tabnormal\tpresent\tnotpresent\t...\t32\t6700\t3.9\tyes\tno\tno\tpoor\tyes\tyes\tckd\n4\t4\t51.0\t80.0\t1.010\t2.0\t0.0\tnormal\tnormal\tnotpresent\tnotpresent\t...\t35\t7300\t4.6\tno\tno\tno\tgood\tno\tno\tckd\n5 rows Ã— 26 columns\n\ndf.columns\nIndex(['id', 'age', 'bp', 'sg', 'al', 'su', 'rbc', 'pc', 'pcc', 'ba', 'bgr',\n       'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc', 'htn', 'dm', 'cad',\n       'appet', 'pe', 'ane', 'classification'],\n      dtype='object')\ndf.info\ndf['pcv'].value_counts()\n41      21\n52      21\n44      19\n48      19\n40      16\n43      14\n42      13\n45      13\n32      12\n36      12\n33      12\n50      12\n28      12\n34      11\n37      11\n30       9\n29       9\n35       9\n46       9\n31       8\n24       7\n39       7\n26       6\n38       5\n53       4\n51       4\n49       4\n47       4\n54       4\n25       3\n27       3\n22       3\n19       2\n23       2\n15       1\n21       1\n17       1\n20       1\n\\t43     1\n18       1\n9        1\n14       1\n\\t?      1\n16       1\nName: pcv, dtype: int64\ndf['wc'].value_counts()\n9800     11\n6700     10\n9200      9\n9600      9\n7200      9\n         ..\n19100     1\n\\t?       1\n12300     1\n14900     1\n12700     1\nName: wc, Length: 92, dtype: int64\ndf['rc'].value_counts()\n5.2    18\n4.5    16\n4.9    14\n4.7    11\n4.8    10\n3.9    10\n4.6     9\n3.4     9\n5.9     8\n5.5     8\n6.1     8\n5.0     8\n3.7     8\n5.3     7\n5.8     7\n5.4     7\n3.8     7\n5.6     6\n4.3     6\n4.2     6\n3.2     5\n4.4     5\n5.7     5\n6.4     5\n5.1     5\n6.2     5\n6.5     5\n4.1     5\n3.6     4\n6.3     4\n6.0     4\n4.0     3\n3.3     3\n4       3\n3.5     3\n2.9     2\n3.1     2\n2.6     2\n2.1     2\n2.5     2\n2.8     2\n3.0     2\n2.7     2\n5       2\n2.3     1\n\\t?     1\n2.4     1\n3       1\n8.0     1\nName: rc, dtype: int64\ndf['dm'].value_counts()\nno       258\nyes      134\n\\tno       3\n\\tyes      2\n yes       1\nName: dm, dtype: int64\ndf['cad'].value_counts()\nno      362\nyes      34\n\\tno      2\nName: cad, dtype: int64\ndf['classification'].value_counts()\nckd       248\nnotckd    150\nckd\\t       2\nName: classification, dtype: int64\ndf['pcv']=df['pcv'].apply(lambda x:x if type(x)==type(3.5) else x.replace('\\t43','43').replace('\\t?','Nan'))\n\n# cleaning \"WC\"\ndf['wc']=df['wc'].apply(lambda x:x if type(x)==type(3.5) else x.replace('\\t?','Nan').replace('\\t6200','6200').replace('\\t8400','8400'))\n\n# cleaning \"RC\"\ndf['rc']=df['rc'].apply(lambda x:x if type(x)==type(3.5) else x.replace('\\t?','Nan'))\n\n# cleaning \"dm\"\ndf['dm']=df['dm'].apply(lambda x:x if type(x)==type(3.5) else x.replace('\\tno','no').replace('\\tyes','yes').replace(' yes','yes'))\n\n# cleaning \"CAD\"\ndf['cad']=df['cad'].apply(lambda x:x if type(x)==type(3.5) else x.replace('\\tno','no'))\n\n# cleaning \"Classification\"\ndf['classification']=df['classification'].apply(lambda x:x if type(x)==type(3.5) else x.replace('ckd\\t','ckd'))\n#explicitly converting numerical columns \nmistyped=[['pcv','rc','wc']]\nfor i in mistyped:\n    df[i]=df[i].astype('float')\ncat_cols=list(df.select_dtypes('object'))\ncat_cols\n['rbc',\n 'pc',\n 'pcc',\n 'ba',\n 'htn',\n 'dm',\n 'cad',\n 'appet',\n 'pe',\n 'ane',\n 'classification']\nnum_cols=list(df.select_dtypes(['int64','float64']))\nnum_cols\n['id',\n 'age',\n 'bp',\n 'sg',\n 'al',\n 'su',\n 'bgr',\n 'bu',\n 'sc',\n 'sod',\n 'pot',\n 'hemo',\n 'pcv',\n 'wc',\n 'rc']\n#handling missing data\ndf.isnull().sum().sort_values(ascending=False)\nrbc               152\nrc                131\nwc                106\npot                88\nsod                87\npcv                71\npc                 65\nhemo               52\nsu                 49\nsg                 47\nal                 46\nbgr                44\nbu                 19\nsc                 17\nbp                 12\nage                 9\nba                  4\npcc                 4\nhtn                 2\ndm                  2\ncad                 2\nane                 1\nappet               1\npe                  1\nid                  0\nclassification      0\ndtype: int64\ndf['rbc'].mode()\n0    normal\ndtype: object\ndf['pc'].mode()\n0    normal\ndtype: object\ndf['pcc'].mode()\n0    notpresent\ndtype: object\ndf['ba'].mode()\n0    notpresent\ndtype: object\ndf['htn'].mode()\n0    no\ndtype: object\ndf['dm'].mode()\n0    no\ndtype: object\ndf['cad'].mode()\n0    no\ndtype: object\ndf['appet'].mode()\n0    good\ndtype: object\ndf['pe'].mode()\n0    no\ndtype: object\ndf['ane'].mode()\n0    no\ndtype: object\ndf['rbc'].fillna('normal',inplace=True)\ndf['pc'].fillna('normal',inplace=True)\ndf['pcc'].fillna('notpresent',inplace=True)\ndf['ba'].fillna('notpresent',inplace=True)\ndf['htn'].fillna('no',inplace=True)\ndf['dm'].fillna('no',inplace=True)\ndf['cad'].fillna('no',inplace=True)\ndf['appet'].fillna('good',inplace=True)\ndf['pe'].fillna('no',inplace=True)\ndf['ane'].fillna('no',inplace=True)\nfor col in num_cols:\n    df[col]=df[col].fillna(df[col].median())\ndf.isna().sum().sort_values(ascending=False)\nid                0\nage               0\nane               0\npe                0\nappet             0\ncad               0\ndm                0\nhtn               0\nrc                0\nwc                0\npcv               0\nhemo              0\npot               0\nsod               0\nsc                0\nbu                0\nbgr               0\nba                0\npcc               0\npc                0\nrbc               0\nsu                0\nal                0\nsg                0\nbp                0\nclassification    0\ndtype: int64\ndf['classification'].unique()\narray(['ckd', 'notckd'], dtype=object)\n#label encoding for target class\ndf['classification']=df['classification'].map({'ckd':1,'notckd':0})\ndf['classification'].unique()\narray([1, 0])\ndf['rbc']=df['rbc'].map({'normal':0,'abnormal':1})\ndf['pc']=df['pc'].map({'normal':0,'abnormal':1})\ndf['pcc']=df['pcc'].map({'notpresent':0,'present':1})\ndf['ba']=df['ba'].map({'notpresent':0,'present':1})\ndf['htn']=df['htn'].map({'no':0,'yes':1})\ndf['dm']=df['dm'].map({'no':0,'yes':1})\ndf['cad']=df['cad'].map({'no':0,'yes':1})\ndf['pe']=df['pe'].map({'no':0,'yes':1})\ndf['ane']=df['ane'].map({'no':0,'yes':1})\ndf['appet']=df['appet'].map({'good':0,'poor':1})\nfrom sklearn.model_selection import train_test_split\nx=df.drop('classification',axis=1)#independent\ny=df['classification']#dependent\n\nX_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)\nprint(\"X_train size {} , X_test size {}\".format(X_train.shape,X_test.shape))\nX_train size (320, 25) , X_test size (80, 25)\nimport warnings\nfrom decimal import Decimal\nimport numpy as np\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nimport matplotlib.pyplot as plt\n# ignore warnings generated due to usage of old version of tensorflow\nwarnings.simplefilter(\"ignore\")\ndf\nid\tage\tbp\tsg\tal\tsu\trbc\tpc\tpcc\tba\t...\tpcv\twc\trc\thtn\tdm\tcad\tappet\tpe\tane\tclassification\n0\t0\t48.0\t80.0\t1.020\t1.0\t0.0\t0\t0\t0\t0\t...\t44.0\t7800.0\t5.2\t1\t1\t0\t0\t0\t0\t1\n1\t1\t7.0\t50.0\t1.020\t4.0\t0.0\t0\t0\t0\t0\t...\t38.0\t6000.0\t4.8\t0\t0\t0\t0\t0\t0\t1\n2\t2\t62.0\t80.0\t1.010\t2.0\t3.0\t0\t0\t0\t0\t...\t31.0\t7500.0\t4.8\t0\t1\t0\t1\t0\t1\t1\n3\t3\t48.0\t70.0\t1.005\t4.0\t0.0\t0\t1\t1\t0\t...\t32.0\t6700.0\t3.9\t1\t0\t0\t1\t1\t1\t1\n4\t4\t51.0\t80.0\t1.010\t2.0\t0.0\t0\t0\t0\t0\t...\t35.0\t7300.0\t4.6\t0\t0\t0\t0\t0\t0\t1\n...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n395\t395\t55.0\t80.0\t1.020\t0.0\t0.0\t0\t0\t0\t0\t...\t47.0\t6700.0\t4.9\t0\t0\t0\t0\t0\t0\t0\n396\t396\t42.0\t70.0\t1.025\t0.0\t0.0\t0\t0\t0\t0\t...\t54.0\t7800.0\t6.2\t0\t0\t0\t0\t0\t0\t0\n397\t397\t12.0\t80.0\t1.020\t0.0\t0.0\t0\t0\t0\t0\t...\t49.0\t6600.0\t5.4\t0\t0\t0\t0\t0\t0\t0\n398\t398\t17.0\t60.0\t1.025\t0.0\t0.0\t0\t0\t0\t0\t...\t51.0\t7200.0\t5.9\t0\t0\t0\t0\t0\t0\t0\n399\t399\t58.0\t80.0\t1.025\t0.0\t0.0\t0\t0\t0\t0\t...\t53.0\t6800.0\t6.1\t0\t0\t0\t0\t0\t0\t0\n400 rows Ã— 26 columns\n\ny = df['classification']\nX = df.drop(['classification','id'], axis = 1)\nX.head()\nage\tbp\tsg\tal\tsu\trbc\tpc\tpcc\tba\tbgr\t...\themo\tpcv\twc\trc\thtn\tdm\tcad\tappet\tpe\tane\n0\t48.0\t80.0\t1.020\t1.0\t0.0\t0\t0\t0\t0\t121.0\t...\t15.4\t44.0\t7800.0\t5.2\t1\t1\t0\t0\t0\t0\n1\t7.0\t50.0\t1.020\t4.0\t0.0\t0\t0\t0\t0\t121.0\t...\t11.3\t38.0\t6000.0\t4.8\t0\t0\t0\t0\t0\t0\n2\t62.0\t80.0\t1.010\t2.0\t3.0\t0\t0\t0\t0\t423.0\t...\t9.6\t31.0\t7500.0\t4.8\t0\t1\t0\t1\t0\t1\n3\t48.0\t70.0\t1.005\t4.0\t0.0\t0\t1\t1\t0\t117.0\t...\t11.2\t32.0\t6700.0\t3.9\t1\t0\t0\t1\t1\t1\n4\t51.0\t80.0\t1.010\t2.0\t0.0\t0\t0\t0\t0\t106.0\t...\t11.6\t35.0\t7300.0\t4.6\t0\t0\t0\t0\t0\t0\n5 rows Ã— 24 columns\n\nFeature Selection\n\n# Building the model\nextra_tree_forest = ExtraTreesClassifier(n_estimators = 5,criterion ='entropy', max_features = 2)\n\n# Training the model\nextra_tree_forest.fit(X, y)\n\n# Computing the importance of each feature\nfeature_importance = extra_tree_forest.feature_importances_\n\n# Normalizing the individual importances\nfeature_importance_normalized = np.std([tree.feature_importances_ for tree in\n\t\t\t\t\t\t\t\t\t\textra_tree_forest.estimators_],\n\t\t\t\t\t\t\t\t\t\taxis = 0)\nplt.figure(figsize=(50,20))\nplt.bar(X.columns, feature_importance_normalized)\n\nplt.xlabel('Feature Labels')\nplt.ylabel('Feature Importances')\nplt.title('Comparison of different Feature Importances')\nplt.show()\n\nfeature_scores=pd.DataFrame(extra_tree_forest.feature_importances_,columns=['Score'],index=X.columns).sort_values(by='Score',ascending=False)\ntop10_feature = feature_scores.nlargest(n=10, columns=['Score'])\nplt.figure(figsize=(20,6))\nprint(top10_feature.index)\ng = sns.barplot(x=top10_feature.index, y=top10_feature['Score'])\np = plt.title('Top 10 Features with Extra Tree Classifier')\np = plt.xlabel('Feature name')\np = plt.ylabel('Extra Tree score')\np = g.set_xticklabels(g.get_xticklabels(), horizontalalignment='right')\nIndex(['hemo', 'htn', 'dm', 'rc', 'pcv', 'sg', 'bgr', 'rbc', 'appet', 'al'], dtype='object')\n\ntop10_feature.index\nIndex(['hemo', 'htn', 'dm', 'rc', 'pcv', 'sg', 'bgr', 'rbc', 'appet', 'al'], dtype='object')\nX.columns\nIndex(['age', 'bp', 'sg', 'al', 'su', 'rbc', 'pc', 'pcc', 'ba', 'bgr', 'bu',\n       'sc', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc', 'htn', 'dm', 'cad',\n       'appet', 'pe', 'ane'],\n      dtype='object')\nfor ele in X.columns:\n  if ele not in top10_feature.index:\n    X = X.drop(ele, axis = 1)\nX.head()\nsg\tal\trbc\tbgr\themo\tpcv\trc\thtn\tdm\tappet\n0\t1.020\t1.0\t0\t121.0\t15.4\t44.0\t5.2\t1\t1\t0\n1\t1.020\t4.0\t0\t121.0\t11.3\t38.0\t4.8\t0\t0\t0\n2\t1.010\t2.0\t0\t423.0\t9.6\t31.0\t4.8\t0\t1\t1\n3\t1.005\t4.0\t0\t117.0\t11.2\t32.0\t3.9\t1\t0\t1\n4\t1.010\t2.0\t0\t106.0\t11.6\t35.0\t4.6\t0\t0\t0\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = None)\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nCLASSIFIER: GradientBoostingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\ngb = GradientBoostingClassifier()\ngb.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of gradient boosting classifier\ngb_acc = accuracy_score(y_test, gb.predict(X_test))\nprint(f\"Training Accuracy of Gradient Boosting Classifier is {accuracy_score(y_train, gb.predict(X_train))}\")\nprint(f\"Test Accuracy of Gradient Boosting Classifier is {gb_acc*100} \\n\")\n\nprint(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, gb.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, gb.predict(X_test))}\")\nTraining Accuracy of Gradient Boosting Classifier is 1.0\nTest Accuracy of Gradient Boosting Classifier is 100.0 \n\nConfusion Matrix :- \n [[40  0]\n [ 0 80]]\n\nClassification Report :- \n               precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        40\n           1       1.00      1.00      1.00        80\n\n    accuracy                           1.00       120\n   macro avg       1.00      1.00      1.00       120\nweighted avg       1.00      1.00      1.00       120\n\nCLASSIFIER: STOCHASTIC GRADIENT BOOSTING CLASSIFIER\n\nsgb = GradientBoostingClassifier(max_depth = 4, subsample = 0.90, max_features = 0.75, n_estimators = 200)\nsgb.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of stochastic gradient boosting classifier\n\nsgb_acc = accuracy_score(y_test, sgb.predict(X_test))\n\nprint(f\"Training Accuracy of Stochastic Gradient Boosting is {accuracy_score(y_train, sgb.predict(X_train))*100}\")\nprint(f\"Test Accuracy of Stochastic Gradient Boosting is {sgb_acc*100} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, sgb.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, sgb.predict(X_test))}\")\nTraining Accuracy of Stochastic Gradient Boosting is 100.0\nTest Accuracy of Stochastic Gradient Boosting is 99.16666666666667 \n\nConfusion Matrix :- \n[[39  1]\n [ 0 80]]\n\nClassification Report :- \n               precision    recall  f1-score   support\n\n           0       1.00      0.97      0.99        40\n           1       0.99      1.00      0.99        80\n\n    accuracy                           0.99       120\n   macro avg       0.99      0.99      0.99       120\nweighted avg       0.99      0.99      0.99       120\n\nCLASSIFIER: EXTRA TREE CLASSIFIER\n\netc = ExtraTreesClassifier()\netc.fit(X_train, y_train)\n\netc_acc = accuracy_score(y_test, etc.predict(X_test))\n\nprint(f\"Training Accuracy of Extra Trees Classifier is {accuracy_score(y_train, etc.predict(X_train))*100}\")\nprint(f\"Test Accuracy of Extra Trees Classifier is {etc_acc*100} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, etc.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, etc.predict(X_test))}\")\nTraining Accuracy of Extra Trees Classifier is 100.0\nTest Accuracy of Extra Trees Classifier is 100.0 \n\nConfusion Matrix :- \n[[40  0]\n [ 0 80]]\n\nClassification Report :- \n               precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        40\n           1       1.00      1.00      1.00        80\n\n    accuracy                           1.00       120\n   macro avg       1.00      1.00      1.00       120\nweighted avg       1.00      1.00      1.00       120\n\nCLASSIFIER: KNN CLASSIFIER\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of knn\nknn_acc = accuracy_score(y_test, knn.predict(X_test))\nprint(f\"Training Accuracy of KNN is {accuracy_score(y_train, knn.predict(X_train))*100}\")\nprint(f\"Test Accuracy of KNN is {knn_acc*100} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, knn.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, knn.predict(X_test))}\")\nTraining Accuracy of KNN is 95.35714285714286\nTest Accuracy of KNN is 95.83333333333334 \n\nConfusion Matrix :- \n[[38  2]\n [ 3 77]]\n\nClassification Report :- \n               precision    recall  f1-score   support\n\n           0       0.93      0.95      0.94        40\n           1       0.97      0.96      0.97        80\n\n    accuracy                           0.96       120\n   macro avg       0.95      0.96      0.95       120\nweighted avg       0.96      0.96      0.96       120\n\nCLASSIFIER: DESICION TREE CLASSIFIER\n\nfrom sklearn.tree import DecisionTreeClassifier\n\ndtc = DecisionTreeClassifier()\ndtc.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of decision tree\n\ndtc_acc = accuracy_score(y_test, dtc.predict(X_test))\n\nprint(f\"Training Accuracy of Decision Tree Classifier is {accuracy_score(y_train, dtc.predict(X_train))*100}\")\nprint(f\"Test Accuracy of Decision Tree Classifier is {dtc_acc*100} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, dtc.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, dtc.predict(X_test))}\")\nTraining Accuracy of Decision Tree Classifier is 100.0\nTest Accuracy of Decision Tree Classifier is 96.66666666666667 \n\nConfusion Matrix :- \n[[39  1]\n [ 3 77]]\n\nClassification Report :- \n               precision    recall  f1-score   support\n\n           0       0.93      0.97      0.95        40\n           1       0.99      0.96      0.97        80\n\n    accuracy                           0.97       120\n   macro avg       0.96      0.97      0.96       120\nweighted avg       0.97      0.97      0.97       120\n\nfrom sklearn.model_selection import GridSearchCV\ngrid_param = {\n    'criterion' : ['gini', 'entropy'],\n    'max_depth' : [3, 5, 7, 10],\n    'splitter' : ['best', 'random'],\n    'min_samples_leaf' : [1, 2, 3, 5, 7],\n    'min_samples_split' : [1, 2, 3, 5, 7],\n    'max_features' : ['auto', 'sqrt', 'log2']\n}\n\ngrid_search_dtc = GridSearchCV(dtc, grid_param, cv = 5, n_jobs = -1, verbose = 1)\ngrid_search_dtc.fit(X_train, y_train)\nFitting 5 folds for each of 1200 candidates, totalling 6000 fits\nGridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=-1,\n             param_grid={'criterion': ['gini', 'entropy'],\n                         'max_depth': [3, 5, 7, 10],\n                         'max_features': ['auto', 'sqrt', 'log2'],\n                         'min_samples_leaf': [1, 2, 3, 5, 7],\n                         'min_samples_split': [1, 2, 3, 5, 7],\n                         'splitter': ['best', 'random']},\n             verbose=1)\n\n# best estimator\ndtc = grid_search_dtc.best_estimator_\n\n# accuracy score, confusion matrix and classification report of decision tree\ndtc_acc = accuracy_score(y_test, dtc.predict(X_test))\n\nprint(f\"Training Accuracy of Decision Tree Classifier is {accuracy_score(y_train, dtc.predict(X_train))*100}\")\nprint(f\"Test Accuracy of Decision Tree Classifier is {dtc_acc*100} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, dtc.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, dtc.predict(X_test))}\")\nTraining Accuracy of Decision Tree Classifier is 98.92857142857143\nTest Accuracy of Decision Tree Classifier is 99.16666666666667 \n\nConfusion Matrix :- \n[[39  1]\n [ 0 80]]\n\nClassification Report :- \n               precision    recall  f1-score   support\n\n           0       1.00      0.97      0.99        40\n           1       0.99      1.00      0.99        80\n\n    accuracy                           0.99       120\n   macro avg       0.99      0.99      0.99       120\nweighted avg       0.99      0.99      0.99       120\n\nCLASSIFIER: RANDOM FOREST CLASSIFIER\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nrd_clf = RandomForestClassifier(criterion = 'entropy', max_depth = 11, max_features = 'auto', min_samples_leaf = 2, min_samples_split = 3, n_estimators = 130)\nrd_clf.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of random forest\n\nrd_clf_acc = accuracy_score(y_test, rd_clf.predict(X_test))\n\nprint(f\"Training Accuracy of Random Forest Classifier is {accuracy_score(y_train, rd_clf.predict(X_train))*100}\")\nprint(f\"Test Accuracy of Random Forest Classifier is {rd_clf_acc*100} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, rd_clf.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, rd_clf.predict(X_test))}\")\nTraining Accuracy of Random Forest Classifier is 98.92857142857143\nTest Accuracy of Random Forest Classifier is 99.16666666666667 \n\nConfusion Matrix :- \n[[39  1]\n [ 0 80]]\n\nClassification Report :- \n               precision    recall  f1-score   support\n\n           0       1.00      0.97      0.99        40\n           1       0.99      1.00      0.99        80\n\n    accuracy                           0.99       120\n   macro avg       0.99      0.99      0.99       120\nweighted avg       0.99      0.99      0.99       120\n\nCLASSIFIER: ADABOOST CLASSIFIER\n\nfrom sklearn.ensemble import AdaBoostClassifier\n\nada = AdaBoostClassifier(base_estimator = dtc)\nada.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of ada boost\n\nada_acc = accuracy_score(y_test, ada.predict(X_test))\n\nprint(f\"Training Accuracy of Ada Boost Classifier is {accuracy_score(y_train, ada.predict(X_train))*100}\")\nprint(f\"Test Accuracy of Ada Boost Classifier is {ada_acc*100} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, ada.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, ada.predict(X_test))}\")\nTraining Accuracy of Ada Boost Classifier is 99.64285714285714\nTest Accuracy of Ada Boost Classifier is 100.0 \n\nConfusion Matrix :- \n[[40  0]\n [ 0 80]]\n\nClassification Report :- \n               precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        40\n           1       1.00      1.00      1.00        80\n\n    accuracy                           1.00       120\n   macro avg       1.00      1.00      1.00       120\nweighted avg       1.00      1.00      1.00       120\n\nCLASSIFIER: XGBOOST CLASSIFIER\n\nfrom xgboost import XGBClassifier\n\nxgb = XGBClassifier(objective = 'binary:logistic', learning_rate = 0.5, max_depth = 5, n_estimators = 150)\nxgb.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of xgboost\n\nxgb_acc = accuracy_score(y_test, xgb.predict(X_test))\n\nprint(f\"Training Accuracy of XgBoost is {accuracy_score(y_train, xgb.predict(X_train))*100}\")\nprint(f\"Test Accuracy of XgBoost is {xgb_acc*100} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, xgb.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, xgb.predict(X_test))}\")\nTraining Accuracy of XgBoost is 99.28571428571429\nTest Accuracy of XgBoost is 98.33333333333333 \n\nConfusion Matrix :- \n[[38  2]\n [ 0 80]]\n\nClassification Report :- \n               precision    recall  f1-score   support\n\n           0       1.00      0.95      0.97        40\n           1       0.98      1.00      0.99        80\n\n    accuracy                           0.98       120\n   macro avg       0.99      0.97      0.98       120\nweighted avg       0.98      0.98      0.98       120\n\nCLASSIFIER: LGBM CLASSIFIER\n\nfrom lightgbm import LGBMClassifier\n\nlgbm = LGBMClassifier(learning_rate = 1)\nlgbm.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of lgbm classifier\n\nlgbm_acc = accuracy_score(y_test, lgbm.predict(X_test))\n\nprint(f\"Training Accuracy of LGBM Classifier is {accuracy_score(y_train, lgbm.predict(X_train))*100}\")\nprint(f\"Test Accuracy of LGBM Classifier is {lgbm_acc*100} \\n\")\n\nprint(f\"{confusion_matrix(y_test, lgbm.predict(X_test))}\\n\")\nprint(classification_report(y_test, lgbm.predict(X_test)))\nTraining Accuracy of LGBM Classifier is 100.0\nTest Accuracy of LGBM Classifier is 99.16666666666667 \n\n[[39  1]\n [ 0 80]]\n\n              precision    recall  f1-score   support\n\n           0       1.00      0.97      0.99        40\n           1       0.99      1.00      0.99        80\n\n    accuracy                           0.99       120\n   macro avg       0.99      0.99      0.99       120\nweighted avg       0.99      0.99      0.99       120\n\nCOMPARISON OF MODELS\n\nmodels = pd.DataFrame({\n    'Model' : [ 'KNN', 'Decision Tree Classifier', 'Random Forest Classifier','ADA Boost Classifier',\n             'Gradient Boosting Classifier', 'Stochastic Gradient Boosting', 'XGBoost', 'Extra Tree Classifier'],\n    'Score' : [knn_acc, dtc_acc, rd_clf_acc, ada_acc, gb_acc, sgb_acc, xgb_acc, etc_acc]\n})\n\nmodels.sort_values(by = 'Score', ascending = False)\nModel\tScore\n3\tADA Boost Classifier\t1.000000\n4\tGradient Boosting Classifier\t1.000000\n7\tExtra Tree Classifier\t1.000000\n1\tDecision Tree Classifier\t0.991667\n2\tRandom Forest Classifier\t0.991667\n5\tStochastic Gradient Boosting\t0.991667\n6\tXGBoost\t0.983333\n0\tKNN\t0.958333\nimport plotly.express as px\npx.bar(data_frame = models, x = 'Score', y = 'Model', color = 'Score', template = 'plotly_dark', \n       title = 'Models Comparison')\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}